{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from pytube import YouTube\n",
    "import whisper\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import uuid\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/youtube-chat/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name='all-MiniLM-L6-v2')\n",
    "metadata_options = {\"hnsw:space\": \"cosine\" }\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(name=\"video-transcription\", metadata=metadata_options, embedding_function=sentence_transformer_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every programming language explained in 15 minutes | Prime Reacts - ThePrimeTime\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=jQiYW3RXkFU\" # Change video URL here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription took 2.447 minutes.\n"
     ]
    }
   ],
   "source": [
    "# transcribe a youtube video\n",
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    youtube = YouTube(YOUTUBE_VIDEO)\n",
    "    audio = youtube.streams.filter(only_audio=True).first()\n",
    "    whisper_model = whisper.load_model(\"base\") #whisper.available_models()\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file = audio.download(output_path=tmpdir)\n",
    "        start_time = time.time()\n",
    "        transcription = whisper_model.transcribe(file, fp16=False)[\"text\"].strip()\n",
    "        end_time = time.time()\n",
    "        with open(\"transcription.txt\", \"w\") as file:\n",
    "            file.write(transcription)\n",
    "        transcription_time = end_time - start_time\n",
    "        print(f\"Transcription took {round(transcription_time/ 60, 3)} minutes.\")\n",
    "else:\n",
    "    with open(\"transcription.txt\") as file:\n",
    "        transcription = file.read()\n",
    "        \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n",
    "documents = text_splitter.split_text(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every language ever assembly a low-level programming language allowing here Wow, we went did this thing does not This is dead serious. Okay, 15 minutes every single language every single language ever I cannot wait to hear about everybody's favorite language synergy Okay, we've got to start with assembly it makes sense It's to give instructions to the computer's hardware you see computers can only\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsert documents into ChromaDB\n",
    "for doc in documents:\n",
    "    uuid_name = uuid.uuid1()\n",
    "    # print(\"document for\", uuid_name)\n",
    "    collection.add(ids=[str(uuid_name)], documents=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-transcription\n",
      "\n",
      "{'hnsw:space': 'cosine'}\n",
      "\n",
      "dict_keys(['ids', 'embeddings', 'metadatas', 'documents', 'uris', 'data', 'included'])\n",
      "\n",
      "[\"Every language ever assembly a low-level programming language allowing here Wow, we went did this thing does not This is dead serious. Okay, 15 minutes every single language every single language ever I cannot wait to hear about everybody's favorite language synergy Okay, we've got to start with assembly it makes sense It's to give instructions to the computer's hardware you see computers can only\", \"computers can only do things in terms of zero or one So assembly was created in order to make computer instructions more workable for human beings This works by using an assembler that translates the human readable code into ones and zeros Assembly is one of the world's first pro almost a canisa's keyboard It's almost a canisa's keyboard back in the 60s this thing time traveled This thing has\", 'This thing has time traveled look at this look at this guy this guy was pro this guy was raw dog and zeros and ones into a computer long before You did anything, okay? You and your JavaScript Okay, this is what this is what a senior dev looks like This is what jack black in an alternative universe looks like Gaming languages it used to be the standard to run super computers back in the day But', \"back in the day But you still find it used currently to work with CPU memory and it's used sometimes in browsers via web assembly Fortran one of Huh Ha Web assembly and assembly are different just saying they're different the world's first high level languages the difference between a high level language and a low level Language was for trend the world's first high level language. I thought I\", 'I thought I thought algo algo algo Algo When did algo I thought algo 69 okay and Fortran oh What about the Z the Z1 language? That was like 1930 1940 yeah, yeah, yeah, yeah, yeah, I thought the Z1 was considered like One of the most modern computers with with with with bullying logic and stuff like that I thought that was like one of the I thought that was like the first is first is but okay,', \"first is but okay, okay Fortran did are aren't you tired of being wrong? No, I never am tired of being wrong Never be tired of being wrong. Okay. I'm a programmer If you're not ready to argue Ususly for hours over things that don't even matter then you're not ready to be a programmer When you can manipulate the computer's memory much more directly It also executes much faster than a high level\", \"than a high level language the drama is is that it's much harder to learn a high level language Is much easier to understand and as a lot of it used much for the total of how hard it is Fortran was created by IBM in the 1950s the name stands for formula translator programming and Fortran would be done by using a punch card Then would be fed into a card reader and would be translated into code\", \"into code that the computer can understand this translating process is called Compiling which basically changes the code that humans can read I can't tell you how many stories I heard in college for my Professors about punch cards and they said the worst of all of the things that happened with punch cards is when you're walking to the machine And one of them told me a story about how they tripped\", 'how they tripped and it was like 25 50 punch cards some large amount tripped and Just threw out all the punch cards just just let them fly had to redo your entire Program from scratch because you tripped imagine just imagine that for a second quick sort this you filthy casual I know Hand number every card skill issue you did have to like that was kind of the that was The lesson as you hand number', \"as you hand number the cards Imagine not numbering them. I know what you did imagine numbering something Imagine living that life where to quick sort come from let's see is that where quick sort came from that is where quick quick Quick sort came from a dude that made quick sort and then was like wow I think I figured out a fast way to do sorting showed his boss and his boss is like you just\"]\n",
      "\n",
      "{'all-MiniLM-L6-v2': SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(collection.name, end='\\n\\n')\n",
    "print(collection.metadata, end='\\n\\n')\n",
    "print(collection.peek().keys(), end='\\n\\n')\n",
    "print(collection.peek()['documents'], end='\\n\\n')\n",
    "print(collection._embedding_function.models, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query_text):\n",
    "    results = collection.query(query_texts=[query_text],n_results=6)\n",
    "    return results['documents']\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "  # Create a list to store all the messages for context\n",
    "  messages = []\n",
    "  messages.append({\"role\": \"system\", \"content\": \"You are a helpful assistant. If the message is a greeting, just respond normally.\" })  \n",
    "  \n",
    "  while True:\n",
    "    # list to store all the retrievals from Chroma\n",
    "    context = []\n",
    "    \n",
    "    # Prompt user for input\n",
    "    message = input(\"User: \")\n",
    "    print(f\"User: {message}\"+'\\n')\n",
    "    \n",
    "    # Exit program if user inputs \"quit\"\n",
    "    if message.lower() == \"quit\":\n",
    "      break\n",
    "    \n",
    "    #retrieve necessary context\n",
    "    context = retrieve_context(message)\n",
    "    # context_string = ', '.join([str(elem) for elem in context])\n",
    "    \n",
    "    message_with_context = f''' \n",
    "    \n",
    "    You are a helpful bot who answers concisely. Use this context: \n",
    "    {context} \n",
    "    \n",
    "    To answer the question: {message}. \n",
    "    \n",
    "    If you don't know the answer from the context, say you don't know.\n",
    "    '''\n",
    "    \n",
    "    # Add each new message to the list\n",
    "    messages.append({\"role\": \"user\", \"content\": message_with_context})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"llama3\",\n",
    "      messages=[{\"role\": \"user\", \"content\": message_with_context}]\n",
    "    )\n",
    "    \n",
    "    # Print the response and add it to the messages list\n",
    "    chat_message = response.choices[0].message.content\n",
    "    print(f\"Bot: {chat_message}\"+'\\n')\n",
    "    messages.append({\"role\": \"assistant\", \"content\": chat_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what's the best programming language according to Prime\n",
      "\n",
      "Bot: I don't know. The text does not provide a clear answer on which programming language is considered the \"best\" by Prime (presumably referring to the author of the text). It mentions various programming languages and their characteristics, but it does not rank or compare them to determine which one is best.\n",
      "\n",
      "User: Why does javascript suck according to Prime?\n",
      "\n",
      "Bot: I think I can help with that!\n",
      "\n",
      "According to the context, it seems like Prime doesn't really think JavaScript \"sucks.\" In fact, they're kind of nostalgic for the old days when memory management was a bigger deal due to limited RAM. They acknowledge that JavaScript still has some issues with memory leaks, but overall, they seem to appreciate its capabilities.\n",
      "\n",
      "So, to answer your question, I don't think Prime thinks JavaScript sucks!\n",
      "\n",
      "User: whats his opinion on Go and Python\n",
      "\n",
      "Bot: According to the context, here is what can be inferred about the person's opinions on Go and Python:\n",
      "\n",
      "* They mention Go as an option they choose over Rust because it's not as complex.\n",
      "* They like that Go doesn't have colored functions and is \"mainly used in service with framework\".\n",
      "* They also mention that they're a fan of Zig, but want to be able to program things to completion, which is why they chose Go.\n",
      "\n",
      "Regarding Python:\n",
      "\n",
      "* They mention that many beginner programmers start with Python as their first programming language because it's easy to learn.\n",
      "* They don't explicitly state their opinion on Python, but seem to have some positive views towards it.\n",
      "\n",
      "I don't know any specific opinions or comparisons between Go and Python in the context provided.\n",
      "\n",
      "User: quit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
